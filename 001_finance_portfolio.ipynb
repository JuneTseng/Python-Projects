{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have embarked on a project to explore the difference between investing in ETFs vs individual stocks\n",
    "\n",
    "The goal of this project is to eventually create an application that houses all of an individual's investment accounts, with the ability to compare against benchmarks, and also visualize predicted gains for retirement, showing the importance of investing early and often.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing initial libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pandas_datareader import data, wb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to explore the idea of getting data via webscraping, since both the Yahoo Finance API and the Google Finance API were deprecated "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webscraping for Ticker Info\n",
    "\n",
    "#### First I will use a single security, VTI in this instance, to make sure I am pulling the data correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://finance.yahoo.com/quote/VTI?p=VTI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(r.text, \"lxml\") \n",
    "#I originally had this as XML, but it broke for some reason.  A switch to LXML quickly fixed this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'151.97'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using the inspect aspect of a webpage, this is simply parsong a little HTML.  \n",
    "soup.find_all(name = 'div', attrs = {'class':'My(6px) Pos(r) smartphone_Mt(6px)'})[0].find('span').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Function\n",
    "#### Here I create a function that allows you to pass any ticker symbol into it and retrieve the current price from yahoo finance's webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseCurrentPrice(stock):\n",
    "    r = requests.get('https://finance.yahoo.com/quote/{}?p={}'.format(stock,stock))\n",
    "    soup = bs4.BeautifulSoup(r.text, \"lxml\")\n",
    "    price = soup.find_all(name = 'div', attrs = {'class':'My(6px) Pos(r) smartphone_Mt(6px)'})[0].find('span').text\n",
    "    return print('The current price of ' + str(stock).upper() + ' is: ' + str(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current price of FB is: 188.89\n"
     ]
    }
   ],
   "source": [
    "parseCurrentPrice('fb')\n",
    "#boom! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will now try to capture historic data for tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty list to add data to.\n",
    "date_list=[]\n",
    "high_list=[]\n",
    "adjclose_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = requests.get('https://finance.yahoo.com/quote/VTI/history?p=VTI')\n",
    "soup2 = bs4.BeautifulSoup(r2.text, \"lxml\")\n",
    "#below I was exploring the ability to change the intervals displayed on the page to show more days\n",
    "#https://finance.yahoo.com/quote/VTI/history?period1=992588400&period2=1570258800&interval=1d&filter=history&frequency=1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oct 15, 2019'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find(name = 'tr', attrs = {'class':'BdT Bdc($seperatorColor) Ta(end) Fz(s) Whs(nw)'}) \\\n",
    "     .find(name = 'td', attrs = {'class': 'Py(10px) Ta(start) Pend(10px)'}).find('span').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tr = soup2.find_all(name = 'tr', attrs = {'class':'BdT Bdc($seperatorColor) Ta(end) Fz(s) Whs(nw)'})\n",
    "#the above code sets the variable tr to the HTML element that holds every days' information.  Use find_all to capture every day\n",
    "#the below function will iterate through every day and pull elements out related to the date\n",
    "for row in tr:\n",
    "    date_list.append(row.find(name = 'td', attrs = {'class': 'Py(10px) Ta(start) Pend(10px)'}).find('span').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oct 15, 2019',\n",
       " 'Oct 14, 2019',\n",
       " 'Oct 11, 2019',\n",
       " 'Oct 10, 2019',\n",
       " 'Oct 09, 2019']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A quick check of the list shows we have successfully filled date_list with the dates corresponding to the market being open\n",
    "date_list[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I tried to run the same function iterating through every day to collect data on the high and adjusted close of each day by adding the following lines to my `for row in tr` function:\n",
    "- high_list.append(row.find_all(name = 'td')[0].text)\n",
    "- adjclose_list.append(row.find_all(name = 'td')[4].text)\n",
    "\n",
    "but I kept running into an error stating the list index out of range.  I realized the issue is with the dividends.  Whenever there was a dividend issued, there would not be highs, lows, and closing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried creating logic that would remove the dividends by finding the specific HTML elements that represented a dividend, and adding logic to only add the days where that element was empty, but got stuck.\n",
    "\n",
    "The following code represents a dividend day:\n",
    "\n",
    "```date_list.append(row.find_all(name = 'td', attrs = {'class': 'Ta(c) Py(10px) Pstart(10px)'}))```\n",
    "\n",
    "      if row.find_all(name = 'td', attrs = {'class': 'Ta(c) Py(10px) Pstart(10px)'}) != '' :\n",
    "        date_list.append(row.find_all(name = 'td', attrs = {'class': 'Ta(c) Py(10px) Pstart(10px)'}))\n",
    "        high_list.append(row.find_all(name = 'td')[0].text)\n",
    "        adjclose_list.append(row.find_all(name = 'td')[4].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At this point, I started to explore beyond Yahoo Finance for historical data, so see if another site's HTML was easier to parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list2 = []\n",
    "r3 = requests.get('https://seekingalpha.com/symbol/VTI/historical-price-quotes')\n",
    "soup3 = bs4.BeautifulSoup(r3.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr><th class=\"quote-date\" data-sort=\"Date\" data-type=\"date\">Date</th><th class=\"quote-open\" data-sort=\"Open\">Open</th><th class=\"quote-high\" data-sort=\"High\">High</th><th class=\"quote-low\" data-sort=\"Low\">Low</th><th class=\"quote-close\" data-sort=\"Close\">Close</th><th class=\"quote-volume\" data-sort=\"Volume\">Volume</th><th class=\"quote-change\" data-sort=\"PercentChange\">Change %</th></tr>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup3.find('table').find_all('tr')\n",
    "# historical-quotes-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Date'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr2 = soup3.find('table').find('tr').find('th').text\n",
    "tr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will come back to that attempt.\n",
    "\n",
    "### I will now attempt to have my program download a csv and read it for historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for win32 chromedriver:77.0.3865.40 in cache\n",
      "Driver found in C:\\Users\\ryanJ\\.wdm\\chromedriver\\77.0.3865.40\\win32/chromedriver.exe\n"
     ]
    }
   ],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "driver.get('https://finance.yahoo.com/quote/VTI/history?p=VTI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data = driver.find_element_by_link_text('Download Data')\n",
    "#download data is the HTML name of the button\n",
    "\n",
    "download_data.click()\n",
    "#click on the download data link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-09-19</th>\n",
       "      <td>150.119995</td>\n",
       "      <td>150.479996</td>\n",
       "      <td>150.009995</td>\n",
       "      <td>150.149994</td>\n",
       "      <td>146.546326</td>\n",
       "      <td>1809800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-20</th>\n",
       "      <td>150.830002</td>\n",
       "      <td>151.470001</td>\n",
       "      <td>150.520004</td>\n",
       "      <td>151.309998</td>\n",
       "      <td>147.678497</td>\n",
       "      <td>1713900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-21</th>\n",
       "      <td>151.820007</td>\n",
       "      <td>151.839996</td>\n",
       "      <td>151.050003</td>\n",
       "      <td>151.160004</td>\n",
       "      <td>147.532104</td>\n",
       "      <td>1986100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-24</th>\n",
       "      <td>150.869995</td>\n",
       "      <td>150.929993</td>\n",
       "      <td>150.270004</td>\n",
       "      <td>150.610001</td>\n",
       "      <td>146.995300</td>\n",
       "      <td>1668600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-25</th>\n",
       "      <td>150.889999</td>\n",
       "      <td>151.070007</td>\n",
       "      <td>150.419998</td>\n",
       "      <td>150.529999</td>\n",
       "      <td>146.917206</td>\n",
       "      <td>2318900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2018-09-19  150.119995  150.479996  150.009995  150.149994  146.546326   \n",
       "2018-09-20  150.830002  151.470001  150.520004  151.309998  147.678497   \n",
       "2018-09-21  151.820007  151.839996  151.050003  151.160004  147.532104   \n",
       "2018-09-24  150.869995  150.929993  150.270004  150.610001  146.995300   \n",
       "2018-09-25  150.889999  151.070007  150.419998  150.529999  146.917206   \n",
       "\n",
       "             Volume  \n",
       "Date                 \n",
       "2018-09-19  1809800  \n",
       "2018-09-20  1713900  \n",
       "2018-09-21  1986100  \n",
       "2018-09-24  1668600  \n",
       "2018-09-25  2318900  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#downloaded it to the directory, now reading it from the CSV on my drive.\n",
    "df = pd.read_csv('VTI.csv', index_col='Date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I realized I need to write a function to have it overwrite the CSV, or have create a variable that increments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incrementer(): \n",
    "    csv = str(VTI.csv(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will come back to this for practice, but will continue to search for better options for getting historical data.\n",
    "\n",
    "In the meantime, I continued with selenium to find the elements by the HTML path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oct 15, 2019 151.03 152.33 150.91 151.97 151.97 2,152,724'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_element_by_xpath('// tr[@class=\"BdT Bdc($seperatorColor) Ta(end) Fz(s) Whs(nw)\"]').text\n",
    "#Xpath=//tagname[@attribute='value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oct 15, 2019'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_element_by_xpath('// tr[@class=\"BdT Bdc($seperatorColor) Ta(end) Fz(s) Whs(nw)\"]/td').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'151.97'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_element_by_xpath('// table[@class=\"W(100%) M(0)\"]') \\\n",
    "      .find_element_by_xpath('// tr[@class=\"BdT Bdc($seperatorColor) Ta(end) Fz(s) Whs(nw)\"]') \\\n",
    "      .find_elements_by_xpath('// td')[4].text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
